{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from enum import StrEnum\n",
    "\n",
    "plt.rcdefaults()\n",
    "plt.rc('axes.formatter', use_mathtext=True)\n",
    "plt.rc('figure', dpi=100)\n",
    "font = {\n",
    "    'family' : 'serif',\n",
    "    'size'   : 12,\n",
    "    'serif':  'cmr10'\n",
    "}\n",
    "plt.rc('font', **font)\n",
    "\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# colors\n",
    "class color(StrEnum):\n",
    "    LeNet = \"green\"\n",
    "    AlexNet = \"blue\"\n",
    "    AlexNetVIB = \"black\"\n",
    "    AlexNetMCDO = \"red\"\n",
    "    AlexNetTH_VIB = \"orange\"\n",
    "    VGG = \"dodgerblue\"\n",
    "    ResNet = \"saddlebrown\"\n",
    "\n",
    "    @classmethod\n",
    "    def from_model_name(cls, model_name):\n",
    "        return cls[model_name].value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_customnet(model_name):\n",
    "    if model_name == \"CustomNet\":\n",
    "        return \"AlexNetTH_VIB\"\n",
    "    return model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = \"/workspace/result/test\"\n",
    "model_paths = os.listdir(test_path)\n",
    "model_path_stg = {}\n",
    "for model_path in model_paths:\n",
    "    model_path_stg[model_path] = glob.glob(f\"{test_path}/{model_path}/**data**/**.csv\", recursive=True)\n",
    "\n",
    "test_dfs = {} \n",
    "for model, path in model_path_stg.items():\n",
    "    test_dfs[model] = [pd.read_csv(filename, index_col=None, header=0) for filename in model_path_stg[model]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.23, 65.88,  1.23,  0.5 ,  0.82,  0.34,  0.04]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(np.mean(test_dfs[\"LeNet\"], axis=0), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[   Test Loss  Test Accuracy  Log Loss  Entropy Reduction  Model Confidence  \\\n",
       " 0       1.15           68.4      1.15               0.47              0.83   \n",
       " \n",
       "    Top 1 Error  Top 5 Error  \n",
       " 0         0.32         0.03  ,\n",
       "    Test Loss  Test Accuracy  Log Loss  Entropy Reduction  Model Confidence  \\\n",
       " 0       1.25          64.89      1.25               0.51              0.81   \n",
       " \n",
       "    Top 1 Error  Top 5 Error  \n",
       " 0         0.35         0.04  ,\n",
       "    Test Loss  Test Accuracy  Log Loss  Entropy Reduction  Model Confidence  \\\n",
       " 0       1.19          67.35      1.18               0.49              0.82   \n",
       " \n",
       "    Top 1 Error  Top 5 Error  \n",
       " 0         0.33         0.03  ,\n",
       "    Test Loss  Test Accuracy  Log Loss  Entropy Reduction  Model Confidence  \\\n",
       " 0       1.28          64.03      1.28               0.53              0.81   \n",
       " \n",
       "    Top 1 Error  Top 5 Error  \n",
       " 0         0.36         0.04  ,\n",
       "    Test Loss  Test Accuracy  Log Loss  Entropy Reduction  Model Confidence  \\\n",
       " 0       1.28          64.73      1.28               0.51              0.81   \n",
       " \n",
       "    Top 1 Error  Top 5 Error  \n",
       " 0         0.35         0.04  ]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dfs[\"LeNet\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cols = ['Test Accuracy', 'Entropy Reduction', 'Model Confidence', 'Top 1 Error', 'Top 5 Error']\n",
    "cols_to_multiply = ['Model Confidence', 'Top 1 Error', 'Top 5 Error']\n",
    "indices = [replace_customnet(model_name=model) for model in test_dfs.keys()]\n",
    "\n",
    "latex_dfs = []\n",
    "df_std_dict = {}\n",
    "for model_name, df in test_dfs.items():\n",
    "\n",
    "    df_mean = pd.concat(df).groupby(level=0).mean()\n",
    "    df_std = pd.concat(df).groupby(level=0).std()\n",
    "    # model_name = replace_customnet(model_name=model_name)\n",
    "\n",
    "    df_mean[cols_to_multiply] = df_mean[cols_to_multiply] * 100\n",
    "    df_std[cols_to_multiply] = df_std[cols_to_multiply] * 100\n",
    "\n",
    "    df_mean = df_mean[test_cols].round(2)\n",
    "    df_std = df_std[test_cols].round(2)\n",
    "\n",
    "    latex_dfs.append(\"$\" + df_mean.astype(str) + \" \\\\pm \" + df_std.astype(str) + \"$\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llllll}\n",
      "\\toprule\n",
      "level_0 & Test Accuracy & Entropy Reduction & Model Confidence & Top 1 Error & Top 5 Error \\\\\n",
      "\\midrule\n",
      "AlexNetTH_VIB & $79.29 \\pm 0.64$ & $0.22 \\pm 0.01$ & $91.6 \\pm 0.55$ & $20.8 \\pm 0.84$ & $1.6 \\pm 0.55$ \\\\\n",
      "AlexNetMCDO & $83.8 \\pm 0.59$ & $0.15 \\pm 0.01$ & $94.4 \\pm 0.55$ & $16.0 \\pm 0.71$ & $1.0 \\pm 0.0$ \\\\\n",
      "VGG & $86.86 \\pm 1.1$ & $0.09 \\pm 0.01$ & $96.8 \\pm 0.45$ & $13.0 \\pm 1.0$ & $1.0 \\pm 0.0$ \\\\\n",
      "LeNet & $65.88 \\pm 1.89$ & $0.5 \\pm 0.02$ & $81.6 \\pm 0.89$ & $34.2 \\pm 1.64$ & $3.6 \\pm 0.55$ \\\\\n",
      "AlexNetVIB & $73.42 \\pm 0.83$ & $0.18 \\pm 0.0$ & $93.0 \\pm 0.0$ & $26.6 \\pm 1.14$ & $3.0 \\pm 0.0$ \\\\\n",
      "AlexNet & $84.21 \\pm 0.44$ & $0.15 \\pm 0.01$ & $94.2 \\pm 0.45$ & $15.8 \\pm 0.45$ & $1.0 \\pm 0.0$ \\\\\n",
      "ResNet & $84.3 \\pm 0.29$ & $0.2 \\pm 0.0$ & $93.0 \\pm 0.0$ & $15.6 \\pm 0.55$ & $1.0 \\pm 0.0$ \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "combined_latex_df = pd.concat(latex_dfs, keys=indices).reset_index(level=0)\n",
    "print(combined_latex_df.to_latex(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CustomNet': [   Test Loss  Test Accuracy  Log Loss  Entropy Reduction  Model Confidence  \\\n",
       "  0        0.9           79.2      0.89               0.23              0.91   \n",
       "  \n",
       "     Top 1 Error  Top 5 Error  \n",
       "  0         0.21         0.02  ,\n",
       "     Test Loss  Test Accuracy  Log Loss  Entropy Reduction  Model Confidence  \\\n",
       "  0       0.92           79.8      0.91               0.21              0.92   \n",
       "  \n",
       "     Top 1 Error  Top 5 Error  \n",
       "  0          0.2         0.01  ,\n",
       "     Test Loss  Test Accuracy  Log Loss  Entropy Reduction  Model Confidence  \\\n",
       "  0       0.94          79.25      0.93               0.22              0.92   \n",
       "  \n",
       "     Top 1 Error  Top 5 Error  \n",
       "  0         0.21         0.01  ,\n",
       "     Test Loss  Test Accuracy  Log Loss  Entropy Reduction  Model Confidence  \\\n",
       "  0       0.92          79.91      0.91               0.21              0.92   \n",
       "  \n",
       "     Top 1 Error  Top 5 Error  \n",
       "  0          0.2         0.02  ,\n",
       "     Test Loss  Test Accuracy  Log Loss  Entropy Reduction  Model Confidence  \\\n",
       "  0       0.95          78.31      0.93               0.23              0.91   \n",
       "  \n",
       "     Top 1 Error  Top 5 Error  \n",
       "  0         0.22         0.02  ],\n",
       " 'AlexNetMCDO': [   Test Loss  Test Accuracy  Log Loss  Entropy Reduction  Model Confidence  \\\n",
       "  0       0.79          83.87      0.78               0.14              0.95   \n",
       "  \n",
       "     Top 1 Error  Top 5 Error  \n",
       "  0         0.16         0.01  ,\n",
       "     Test Loss  Test Accuracy  Log Loss  Entropy Reduction  Model Confidence  \\\n",
       "  0       0.75          82.92      0.75               0.16              0.94   \n",
       "  \n",
       "     Top 1 Error  Top 5 Error  \n",
       "  0         0.17         0.01  ,\n",
       "     Test Loss  Test Accuracy  Log Loss  Entropy Reduction  Model Confidence  \\\n",
       "  0       0.73          84.51      0.73               0.14              0.94   \n",
       "  \n",
       "     Top 1 Error  Top 5 Error  \n",
       "  0         0.15         0.01  ,\n",
       "     Test Loss  Test Accuracy  Log Loss  Entropy Reduction  Model Confidence  \\\n",
       "  0       0.78          84.06      0.78               0.14              0.95   \n",
       "  \n",
       "     Top 1 Error  Top 5 Error  \n",
       "  0         0.16         0.01  ,\n",
       "     Test Loss  Test Accuracy  Log Loss  Entropy Reduction  Model Confidence  \\\n",
       "  0       0.76          83.62      0.75               0.15              0.94   \n",
       "  \n",
       "     Top 1 Error  Top 5 Error  \n",
       "  0         0.16         0.01  ],\n",
       " 'VGG': [   Test Loss  Test Accuracy  Log Loss  Entropy Reduction  Model Confidence  \\\n",
       "  0       0.65          87.59      0.65               0.09              0.97   \n",
       "  \n",
       "     Top 1 Error  Top 5 Error  \n",
       "  0         0.12         0.01  ,\n",
       "     Test Loss  Test Accuracy  Log Loss  Entropy Reduction  Model Confidence  \\\n",
       "  0       0.63          88.04      0.63               0.08              0.97   \n",
       "  \n",
       "     Top 1 Error  Top 5 Error  \n",
       "  0         0.12         0.01  ,\n",
       "     Test Loss  Test Accuracy  Log Loss  Entropy Reduction  Model Confidence  \\\n",
       "  0       0.71          87.27      0.71               0.08              0.97   \n",
       "  \n",
       "     Top 1 Error  Top 5 Error  \n",
       "  0         0.13         0.01  ,\n",
       "     Test Loss  Test Accuracy  Log Loss  Entropy Reduction  Model Confidence  \\\n",
       "  0       0.77          85.84      0.77               0.09              0.97   \n",
       "  \n",
       "     Top 1 Error  Top 5 Error  \n",
       "  0         0.14         0.01  ,\n",
       "     Test Loss  Test Accuracy  Log Loss  Entropy Reduction  Model Confidence  \\\n",
       "  0       0.77          85.56      0.77                0.1              0.96   \n",
       "  \n",
       "     Top 1 Error  Top 5 Error  \n",
       "  0         0.14         0.01  ],\n",
       " 'LeNet': [   Test Loss  Test Accuracy  Log Loss  Entropy Reduction  Model Confidence  \\\n",
       "  0       1.15           68.4      1.15               0.47              0.83   \n",
       "  \n",
       "     Top 1 Error  Top 5 Error  \n",
       "  0         0.32         0.03  ,\n",
       "     Test Loss  Test Accuracy  Log Loss  Entropy Reduction  Model Confidence  \\\n",
       "  0       1.25          64.89      1.25               0.51              0.81   \n",
       "  \n",
       "     Top 1 Error  Top 5 Error  \n",
       "  0         0.35         0.04  ,\n",
       "     Test Loss  Test Accuracy  Log Loss  Entropy Reduction  Model Confidence  \\\n",
       "  0       1.19          67.35      1.18               0.49              0.82   \n",
       "  \n",
       "     Top 1 Error  Top 5 Error  \n",
       "  0         0.33         0.03  ,\n",
       "     Test Loss  Test Accuracy  Log Loss  Entropy Reduction  Model Confidence  \\\n",
       "  0       1.28          64.03      1.28               0.53              0.81   \n",
       "  \n",
       "     Top 1 Error  Top 5 Error  \n",
       "  0         0.36         0.04  ,\n",
       "     Test Loss  Test Accuracy  Log Loss  Entropy Reduction  Model Confidence  \\\n",
       "  0       1.28          64.73      1.28               0.51              0.81   \n",
       "  \n",
       "     Top 1 Error  Top 5 Error  \n",
       "  0         0.35         0.04  ],\n",
       " 'AlexNetVIB': [   Test Loss  Test Accuracy  Log Loss  Entropy Reduction  Model Confidence  \\\n",
       "  0       1.45           74.6      1.42               0.18              0.93   \n",
       "  \n",
       "     Top 1 Error  Top 5 Error  \n",
       "  0         0.25         0.03  ,\n",
       "     Test Loss  Test Accuracy  Log Loss  Entropy Reduction  Model Confidence  \\\n",
       "  0       1.69          72.38      1.64               0.18              0.93   \n",
       "  \n",
       "     Top 1 Error  Top 5 Error  \n",
       "  0         0.28         0.03  ,\n",
       "     Test Loss  Test Accuracy  Log Loss  Entropy Reduction  Model Confidence  \\\n",
       "  0       1.61          73.42      1.57               0.17              0.93   \n",
       "  \n",
       "     Top 1 Error  Top 5 Error  \n",
       "  0         0.27         0.03  ,\n",
       "     Test Loss  Test Accuracy  Log Loss  Entropy Reduction  Model Confidence  \\\n",
       "  0       1.65          72.98       1.6               0.18              0.93   \n",
       "  \n",
       "     Top 1 Error  Top 5 Error  \n",
       "  0         0.27         0.03  ,\n",
       "     Test Loss  Test Accuracy  Log Loss  Entropy Reduction  Model Confidence  \\\n",
       "  0       1.58          73.71      1.54               0.18              0.93   \n",
       "  \n",
       "     Top 1 Error  Top 5 Error  \n",
       "  0         0.26         0.03  ],\n",
       " 'AlexNet': [   Test Loss  Test Accuracy  Log Loss  Entropy Reduction  Model Confidence  \\\n",
       "  0        0.7          84.41       0.7               0.15              0.94   \n",
       "  \n",
       "     Top 1 Error  Top 5 Error  \n",
       "  0         0.16         0.01  ,\n",
       "     Test Loss  Test Accuracy  Log Loss  Entropy Reduction  Model Confidence  \\\n",
       "  0       0.74          83.99      0.73               0.16              0.94   \n",
       "  \n",
       "     Top 1 Error  Top 5 Error  \n",
       "  0         0.16         0.01  ,\n",
       "     Test Loss  Test Accuracy  Log Loss  Entropy Reduction  Model Confidence  \\\n",
       "  0        0.7          84.66       0.7               0.14              0.95   \n",
       "  \n",
       "     Top 1 Error  Top 5 Error  \n",
       "  0         0.15         0.01  ,\n",
       "     Test Loss  Test Accuracy  Log Loss  Entropy Reduction  Model Confidence  \\\n",
       "  0       0.72          84.44      0.72               0.15              0.94   \n",
       "  \n",
       "     Top 1 Error  Top 5 Error  \n",
       "  0         0.16         0.01  ,\n",
       "     Test Loss  Test Accuracy  Log Loss  Entropy Reduction  Model Confidence  \\\n",
       "  0        0.8          83.55       0.8               0.14              0.94   \n",
       "  \n",
       "     Top 1 Error  Top 5 Error  \n",
       "  0         0.16         0.01  ],\n",
       " 'ResNet': [   Test Loss  Test Accuracy  Log Loss  Entropy Reduction  Model Confidence  \\\n",
       "  0       0.61          83.85      0.61               0.21              0.93   \n",
       "  \n",
       "     Top 1 Error  Top 5 Error  \n",
       "  0         0.16         0.01  ,\n",
       "     Test Loss  Test Accuracy  Log Loss  Entropy Reduction  Model Confidence  \\\n",
       "  0       0.61          84.56      0.61                0.2              0.93   \n",
       "  \n",
       "     Top 1 Error  Top 5 Error  \n",
       "  0         0.15         0.01  ,\n",
       "     Test Loss  Test Accuracy  Log Loss  Entropy Reduction  Model Confidence  \\\n",
       "  0       0.63          84.17      0.62                0.2              0.93   \n",
       "  \n",
       "     Top 1 Error  Top 5 Error  \n",
       "  0         0.16         0.01  ,\n",
       "     Test Loss  Test Accuracy  Log Loss  Entropy Reduction  Model Confidence  \\\n",
       "  0        0.6          84.39       0.6                0.2              0.93   \n",
       "  \n",
       "     Top 1 Error  Top 5 Error  \n",
       "  0         0.16         0.01  ,\n",
       "     Test Loss  Test Accuracy  Log Loss  Entropy Reduction  Model Confidence  \\\n",
       "  0        0.6          84.51       0.6                0.2              0.93   \n",
       "  \n",
       "     Top 1 Error  Top 5 Error  \n",
       "  0         0.15         0.01  ]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Test Loss', 'Test Accuracy', 'Log Loss', 'Entropy Reduction',\n",
       "       'Model Confidence', 'Top 1 Error', 'Top 5 Error'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_m.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['Model Confidence', 'Top 1 Error', 'Top 5 Error'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_m[cols_to_multiply] \u001b[38;5;241m=\u001b[39m \u001b[43mdf_m\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcols_to_multiply\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[1;32m      2\u001b[0m df_s[cols_to_multiply] \u001b[38;5;241m=\u001b[39m df_s[cols_to_multiply] \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.13/site-packages/pandas/core/frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.13/site-packages/pandas/core/indexes/base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6200\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.13/site-packages/pandas/core/indexes/base.py:6249\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nmissing:\n\u001b[1;32m   6248\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m nmissing \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(indexer):\n\u001b[0;32m-> 6249\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6251\u001b[0m     not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m   6252\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Index(['Model Confidence', 'Top 1 Error', 'Top 5 Error'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "df_m[cols_to_multiply] = df_m[cols_to_multiply] * 100\n",
    "df_s[cols_to_multiply] = df_s[cols_to_multiply] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_s = df_s.loc[['Test Accuracy', 'Entropy Reduction',\n",
    "       'Model Confidence', 'Top 1 Error', 'Top 5 Error']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"$\" + df_m.astype(str) + \" \\\\pm \" + df_s.astype(str) + \"$\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrr}\n",
      "\\toprule\n",
      " & Test Accuracy & Entropy Reduction & Model Confidence & Top 1 Error & Top 5 Error \\\\\n",
      "\\midrule\n",
      "AlexNetTH_VIB & 0.570000 & 0.010000 & 0.000000 & 0.010000 & 0.000000 \\\\\n",
      "AlexNetMCDO & 0.530000 & 0.010000 & 0.000000 & 0.010000 & 0.000000 \\\\\n",
      "VGG & 0.980000 & 0.010000 & 0.000000 & 0.010000 & 0.000000 \\\\\n",
      "LeNet & 1.690000 & 0.020000 & 0.010000 & 0.010000 & 0.000000 \\\\\n",
      "AlexNetVIB & 0.740000 & 0.000000 & 0.000000 & 0.010000 & 0.000000 \\\\\n",
      "AlexNet & 0.390000 & 0.010000 & 0.000000 & 0.000000 & 0.000000 \\\\\n",
      "ResNet & 0.260000 & 0.000000 & 0.000000 & 0.000000 & 0.000000 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(df_s.T.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
